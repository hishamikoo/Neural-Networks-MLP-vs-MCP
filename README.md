# ğŸ§ ğŸ¤– Neural Networks: MLP vs. MCP  

ğŸ“„ **Project Report**: [Read the Full Report ğŸ“‘](https://github.com/hishamikoo/Neural-Networks-MLP-vs-MCP/blob/main/MLP%20vs%20MCP%20-%20Report.pdf)  

## ğŸ“Œ Overview  
This research explores the performance of neural networksâ€”**Multi-Layer Perceptron (MLP) ğŸ—ï¸** vs. **Multi-Class Perceptron (MCP) ğŸ”€**compared to traditional classifiers like **K-Nearest Neighbors (KNN) ğŸ“** and **NaÃ¯ve Bayes ğŸ²**.  

## ğŸ” Key Insights  
ğŸ“‰ **MLP struggles with deeper layers**: Despite using a sophisticated architecture, MLP achieved just **~45% accuracy**, which is **lower** than KNN and NaÃ¯ve Bayes. However, with **only 1 hidden layer**, MLP performed significantly better.  

ğŸ“Š **Why did this happen?**  
- ğŸš§ **Model complexity** led to overfitting and poor generalization  
- ğŸ” **KNN leveraged PCA & cross-validation** for **better feature representation**  
- ğŸ¯ **NaÃ¯ve Bayes remained stable** without the need for heavy tuning  

## âš–ï¸ Performance Comparison  
| Model | Strengths ğŸ’ª | Weaknesses âš ï¸ |
|--------|------------|--------------|
| **MLP (Multi-Layer Perceptron) ğŸ—ï¸** | Can model complex relationships | Overfitting, needs hyperparameter tuning |
| **MCP (Multi-Class Perceptron) ğŸ”€** | Simpler and faster than MLP | Struggles with non-linearly separable data |
| **KNN (K-Nearest Neighbors) ğŸ“** | Works well with PCA & tuning | Sensitive to noisy data & computationally expensive |
| **NaÃ¯ve Bayes ğŸ²** | Fast, interpretable, and works well with categorical data | Assumes feature independence, limiting real-world performance |

### ğŸ† Best Performing Model: **KNN**  
- ğŸ“ˆ **Optimal accuracy** with **K values between 6-8**  
- ğŸ”¬ **Best training-testing split**: **60:40**  

## ğŸš€ Improving Neural Network Performance  
To enhance MLPâ€™s accuracy, we suggest:  
âœ… **Hyperparameter tuning** (e.g., grid search, learning rate adjustments)  
âœ… **Regularization techniques** (e.g., dropout, L2 regularization)  
âœ… **Feature engineering** (optimizing input features for better representation)  
âœ… **Alternative architectures** (e.g., CNNs or transformer-based models for more complex tasks)  

## ğŸ¯ Conclusion  
This study emphasizes the **importance of model selection** for different datasets. While **KNN and NaÃ¯ve Bayes** performed best for the **Palmer Penguins dataset**, **MLP has great potential** for more **complex** applications **if optimized correctly**.  

ğŸ”¬ **Key Takeaway:** **Simple models can often outperform deep learning when data and hyperparameters are not optimized effectively.**  
